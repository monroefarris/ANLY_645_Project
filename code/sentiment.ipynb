{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Sentiment Analysis using VADER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading appropriate packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/monroefarris/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in confessional data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "    Episode  Day  Speaker                                               Text\n",
      "0        1    1     Rudy  Paddling over, uh, we had two or three of thos...\n",
      "1        1    1    Kelly  He was yelling at everybody â€œLet's lose the bo...\n",
      "2        1    1   Ramona  I don't like being on the water all that much....\n",
      "3        1    1     Dirk  Rich, um, I appreciate what he's trying to do ...\n",
      "4        1    1  Richard  I'm good to go survival wise. People wise, it'...\n",
      "\n",
      "Number of times each player talked in a confessional\n",
      "    index  Speaker  Times Talked\n",
      "0      0     B.B.            11\n",
      "1      1  Colleen            54\n",
      "2      2     Dirk            11\n",
      "3      3  Gervase            56\n",
      "4      4     Greg            35\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "season = \"season_1\"\n",
    "\n",
    "conf_data = pd.read_csv(data_dir + season + '/confessionals_season_1.csv')\n",
    "print('Data\\n',conf_data.head())\n",
    "\n",
    "num_talked = conf_data.groupby('Speaker').count().reset_index()\n",
    "num_talked = num_talked[['Speaker', 'Episode']].rename(columns = {'Episode': 'Times Talked'}).reset_index()\n",
    "print('\\nNumber of times each player talked in a confessional\\n', num_talked.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Sentiment Analysis \n",
    "\n",
    "- Calculates average sentiment score for the confessional \n",
    "- Bins the aggregate score into either positive or negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic VADER sentiment analysis \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "conf_data['scores'] = conf_data['Text'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "# getting aggregate score for the confessional\n",
    "conf_data['compound']  = conf_data['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "# binning aggregate score into either positive or negative \n",
    "conf_data['comp_score'] = conf_data['compound'].apply(lambda c: 'positive' if c >=0 else 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats\n",
    "- Returns average sentiment score for each player in a season \n",
    "- Returns number of confessionals per player that are negative or positive over the course of the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Speaker  compound\n",
      "0     B.B. -0.024155\n",
      "1  Colleen  0.333902\n",
      "2     Dirk  0.456345\n",
      "3  Gervase  0.310037\n",
      "4     Greg  0.542760\n",
      "   Speaker comp_score  counts\n",
      "0     B.B.   negative       5\n",
      "1     B.B.   positive       6\n",
      "2  Colleen   negative      11\n",
      "3  Colleen   positive      43\n",
      "4     Dirk   negative       3\n"
     ]
    }
   ],
   "source": [
    "# average sentiment score of a player's confessionals for a season\n",
    "avg_sentiment = conf_data.groupby('Speaker')['compound'].mean().reset_index()\n",
    "print(avg_sentiment[['Speaker', 'compound']].head())\n",
    "\n",
    "# number of confessionals over the course of a season by language bin\n",
    "lang_overall = conf_data.groupby(['Speaker', 'comp_score']).count().reset_index()\n",
    "lang_overall = lang_overall.rename(columns = {'compound': 'counts'})\n",
    "print(lang_overall[['Speaker', 'comp_score', 'counts']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Player Mentions\n",
    "- Goal: See how many times a speaker mentions other players, and look at sentiment of the statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gossip Score\n",
    "- How often the speaker in the confessionals is talking about other players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Speaker  gossip_score\n",
      "0   Stacey            16\n",
      "1   Ramona            15\n",
      "2    Susan            14\n",
      "3  Colleen            13\n",
      "4  Gervase            12\n"
     ]
    }
   ],
   "source": [
    "# getting player names\n",
    "speakers = conf_data['Speaker'].unique()\n",
    "\n",
    "# counting number of times a player is mentioned \n",
    "for speaker in speakers:\n",
    "    conf_data['count_' + speaker] = conf_data.Text.str.count(speaker)\n",
    "\n",
    "mentions_df = conf_data.drop(columns = ['Text', 'scores'])\n",
    "\n",
    "# getting total number of times the speaker mentioned another player \n",
    "mentions_df['total_mentions'] = mentions_df.iloc[:, -len(speakers):].sum(axis = 1)\n",
    "total_mentions = mentions_df.groupby('Speaker')['total_mentions'].sum().reset_index()\n",
    "\n",
    "# normalizing number of player mentions by number of times the player spoke in the confessional \n",
    "gossip_score = total_mentions.merge(num_talked, on = 'Speaker').reset_index(drop = True)\n",
    "gossip_score['normalized_mentions'] = gossip_score['total_mentions'] / gossip_score['Times Talked']\n",
    "\n",
    "# calculating gossip score \n",
    "gossip_score = gossip_score[['Speaker', 'normalized_mentions']].sort_values(by = ['normalized_mentions'], ascending=False).reset_index(drop= True)\n",
    "gossip_score['gossip_score_idx'] = gossip_score.index\n",
    "gossip_score['gossip_score'] = len(gossip_score) - gossip_score['gossip_score_idx']\n",
    "print(gossip_score[['Speaker', 'gossip_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Score\n",
    "- How often a player is mentioned by the other players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  player_mentioned  value  popularity_score\n",
      "0            Kelly     52                15\n",
      "1             Sean     52                14\n",
      "2             Greg     31                13\n",
      "3            Jenna     24                12\n",
      "4          Gervase     18                11\n"
     ]
    }
   ],
   "source": [
    "mentions_cols = mentions_df.iloc[: , -len(speakers):-1].columns\n",
    "mentions_df = pd.melt(mentions_df, id_vars=['Episode', 'Day', 'Speaker'], value_vars = mentions_cols).reset_index(drop = True)\n",
    "\n",
    "popularity_score = mentions_df.groupby('variable')['value'].sum().reset_index()\n",
    "popularity_score = popularity_score.rename(columns = {'variable': 'player_mentioned'})\n",
    "popularity_score[['tmp', 'player_mentioned']] = popularity_score['player_mentioned'].str.split('_', expand=True)\n",
    "\n",
    "popularity_score = popularity_score[['player_mentioned', 'value']].sort_values(by = ['value'], ascending=False).reset_index(drop= True)\n",
    "popularity_score['popularity_score_idx'] = popularity_score.index\n",
    "popularity_score['popularity_score'] = len(popularity_score) - popularity_score['popularity_score_idx']\n",
    "\n",
    "print(popularity_score[['player_mentioned', 'value', 'popularity_score']].head())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa3086612d71023ea6bd20cc6c5bbcf1cbba35b1e4a01dc87ce94ea3ec71eb10"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
