{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Sentiment Analysis using VADER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading appropriate packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/monroefarris/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in confessional data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "    Episode  Day  Speaker                                               Text\n",
      "0        1    1     Rudy  Paddling over, uh, we had two or three of thos...\n",
      "1        1    1    Kelly  He was yelling at everybody â€œLet's lose the bo...\n",
      "2        1    1   Ramona  I don't like being on the water all that much....\n",
      "3        1    1     Dirk  Rich, um, I appreciate what he's trying to do ...\n",
      "4        1    1  Richard  I'm good to go survival wise. People wise, it'...\n",
      "\n",
      "Number of times each player talked in a confessional\n",
      "    Speaker  Times Talked\n",
      "0     B.B.            11\n",
      "1  Colleen            54\n",
      "2     Dirk            11\n",
      "3  Gervase            56\n",
      "4     Greg            35\n",
      "   Speaker num_episodes\n",
      "0    Kelly           13\n",
      "1     Rudy           13\n",
      "2    Susan           13\n",
      "3  Richard           13\n",
      "7     Sean           12\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/\"\n",
    "season = \"season_1\"\n",
    "\n",
    "conf_data = pd.read_csv(data_dir + season + '/confessionals_season_1.csv')\n",
    "print('Data\\n',conf_data.head())\n",
    "\n",
    "num_talked = conf_data.groupby('Speaker').count().reset_index()\n",
    "num_talked = num_talked[['Speaker', 'Episode']].rename(columns = {'Episode': 'Times Talked'}).reset_index(drop = True)\n",
    "print('\\nNumber of times each player talked in a confessional\\n', num_talked.head())\n",
    "\n",
    "num_episodes = conf_data[['Speaker', 'Episode']].drop_duplicates().sort_values(by = 'Episode', ascending = False).reset_index(drop = True)\n",
    "num_episodes['num_episodes'] = ''\n",
    "\n",
    "for i in range(len(num_episodes)):\n",
    "    if num_episodes['num_episodes'][i] == '':\n",
    "        num_episodes['num_episodes'] = np.where(num_episodes['Speaker']  == num_episodes['Speaker'][i], num_episodes['Episode'][i], num_episodes['num_episodes'])\n",
    "\n",
    "num_episodes = num_episodes[['Speaker', 'num_episodes']].drop_duplicates()\n",
    "\n",
    "print(num_episodes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Sentiment Analysis \n",
    "\n",
    "- Calculates average sentiment score for the confessional \n",
    "- Bins the aggregate score into either positive or negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic VADER sentiment analysis \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "conf_data['scores'] = conf_data['Text'].apply(lambda review: sid.polarity_scores(review))\n",
    "\n",
    "# getting aggregate score for the confessional\n",
    "conf_data['compound']  = conf_data['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "# binning aggregate score into either positive or negative \n",
    "conf_data['comp_score'] = conf_data['compound'].apply(lambda c: 'positive' if c >=0 else 'negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats\n",
    "- Returns average sentiment score for each player in a season \n",
    "- Returns number of confessionals per player that are negative or positive over the course of the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Speaker  compound\n",
      "0     B.B. -0.024155\n",
      "1  Colleen  0.333902\n",
      "2     Dirk  0.456345\n",
      "3  Gervase  0.310037\n",
      "4     Greg  0.542760\n",
      "   Speaker comp_score  counts\n",
      "0     B.B.   negative       5\n",
      "1     B.B.   positive       6\n",
      "2  Colleen   negative      11\n",
      "3  Colleen   positive      43\n",
      "4     Dirk   negative       3\n"
     ]
    }
   ],
   "source": [
    "# average sentiment score of a player's confessionals for a season\n",
    "avg_sentiment = conf_data.groupby('Speaker')['compound'].mean().reset_index()\n",
    "print(avg_sentiment[['Speaker', 'compound']].head())\n",
    "\n",
    "# number of confessionals over the course of a season by language bin\n",
    "lang_overall = conf_data.groupby(['Speaker', 'comp_score']).count().reset_index()\n",
    "lang_overall = lang_overall.rename(columns = {'compound': 'counts'})\n",
    "\n",
    "lang_overall = lang_overall[['Speaker', 'comp_score', 'counts']]\n",
    "print(lang_overall.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Player Mentions\n",
    "- Goal: See how many times a speaker mentions other players, and look at sentiment of the statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gossip Score\n",
    "- How often the speaker in the confessionals is talking about other players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Speaker  num_confessionals_mentioning_player_norm  gossip_score\n",
      "0   Stacey                                  1.000000            16\n",
      "1   Ramona                                  0.894737            15\n",
      "2    Susan                                  0.690141            14\n",
      "3  Colleen                                  0.685185            13\n",
      "4  Gervase                                  0.642857            12\n"
     ]
    }
   ],
   "source": [
    "# getting player names\n",
    "speakers = conf_data['Speaker'].unique()\n",
    "\n",
    "# counting number of times a player is mentioned \n",
    "for speaker in speakers:\n",
    "    conf_data['count_' + speaker] = conf_data.Text.str.count(speaker)\n",
    "\n",
    "mentions_df = conf_data.drop(columns = ['Text', 'scores'])\n",
    "\n",
    "# getting total number of times the speaker mentioned another player \n",
    "mentions_df['total_mentions'] = mentions_df.iloc[:, -len(speakers):].sum(axis = 1)\n",
    "total_mentions = mentions_df.groupby('Speaker')['total_mentions'].sum().reset_index()\n",
    "\n",
    "# normalizing number of player mentions by number of times the player spoke in the confessional \n",
    "gossip_score = total_mentions.merge(num_talked, on = 'Speaker').reset_index(drop = True)\n",
    "gossip_score['num_confessionals_mentioning_player_norm'] = gossip_score['total_mentions'] / gossip_score['Times Talked']\n",
    "\n",
    "# calculating gossip score \n",
    "gossip_score = gossip_score[['Speaker', 'num_confessionals_mentioning_player_norm']].sort_values(by = ['num_confessionals_mentioning_player_norm'], ascending=False).reset_index(drop= True)\n",
    "gossip_score['gossip_score_idx'] = gossip_score.index\n",
    "gossip_score['gossip_score'] = len(gossip_score) - gossip_score['gossip_score_idx']\n",
    "\n",
    "gossip_score = gossip_score[['Speaker', 'num_confessionals_mentioning_player_norm', 'gossip_score']]\n",
    "print(gossip_score.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Score\n",
    "- How often a player is mentioned by the other players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Speaker normalized_mentions  popularity_score\n",
      "0    B.B.                 7.5                15\n",
      "1    Sean             4.33333                14\n",
      "2   Kelly                   4                13\n",
      "3    Greg               3.875                12\n",
      "4  Stacey             3.33333                11\n"
     ]
    }
   ],
   "source": [
    "mentions_cols = mentions_df.iloc[: , -len(speakers):-1].columns\n",
    "mentions_df = pd.melt(mentions_df, id_vars=['Episode', 'Day', 'Speaker'], value_vars = mentions_cols).reset_index(drop = True)\n",
    "\n",
    "popularity_score = mentions_df.groupby('variable')['value'].sum().reset_index()\n",
    "popularity_score = popularity_score.rename(columns = {'variable': 'player_mentioned'})\n",
    "popularity_score[['tmp', 'player_mentioned']] = popularity_score['player_mentioned'].str.split('_', expand=True)\n",
    "\n",
    "# # normalizing number of player mentions by number of times the player spoke in the confessional \n",
    "num_episodes = num_episodes.rename(columns = {'Speaker': 'player_mentioned'})\n",
    "popularity_score = popularity_score.merge(num_episodes, on = 'player_mentioned').reset_index(drop = True)\n",
    "popularity_score['normalized_mentions'] = popularity_score['value'] / popularity_score['num_episodes']\n",
    "\n",
    "popularity_score = popularity_score[['player_mentioned', 'normalized_mentions']].sort_values(by = ['normalized_mentions'], ascending=False).reset_index(drop= True)\n",
    "popularity_score['popularity_score_idx'] = popularity_score.index\n",
    "popularity_score['popularity_score'] = len(popularity_score) - popularity_score['popularity_score_idx']\n",
    "\n",
    "popularity_score = popularity_score[['player_mentioned', 'normalized_mentions', 'popularity_score']]\n",
    "popularity_score = popularity_score.rename(columns={'player_mentioned':'Speaker'})\n",
    "\n",
    "print(popularity_score.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging everything together to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = gossip_score.merge(popularity_score, on = 'Speaker')\n",
    "final_df = final_df.merge(avg_sentiment, on = 'Speaker')\n",
    "final_df = final_df.rename(columns = {'Speaker': 'Player'})\n",
    "\n",
    "output_dir = \"results\"\n",
    "\n",
    "final_df.to_csv(data_dir + season + \"/\" + output_dir + '/results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Do / Track \n",
    "\n",
    "- improve search for player mentions \n",
    "    - i.e. \"Ricky\" instead of \"Richard\" \n",
    "- revise custom metrics to better encompass what we are looking for \n",
    "\n",
    "- think about other ways to use sentiment as opposed to overall sentiment value for a season"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa3086612d71023ea6bd20cc6c5bbcf1cbba35b1e4a01dc87ce94ea3ec71eb10"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
